# ğŸ©º Breast Cancer Prediction (IDC Classification)

Predicting **Invasive Ductal Carcinoma (IDC)** in histopathology tissue patches using **Deep Learning**
(Final accuracy: **86.05%** on unseen patient test set)

---

## ğŸ“Œ Overview

Invasive Ductal Carcinoma accounts for nearly **80% of all breast cancer cases**, making early detection essential.
This project builds a **deep learning pipeline** to classify histopathology image patches as:

* **0 â€” Benign (Healthy Tissue)**
* **1 â€” IDC-Positive (Cancerous Tissue)**

Using a **ResNet18** model with transfer learning, weighted loss, and cyclical learning rate scheduling, this work demonstrates how AI can support pathologists by reducing manual workload and improving diagnostic consistency.

---

## ğŸš€ Key Features

* âœ”ï¸ **Patient-level dataset splitting** to avoid data leakage
* âœ”ï¸ **ResNet18 transfer learning** with a custom classification head
* âœ”ï¸ **Weighted Cross-Entropy Loss** for class imbalance
* âœ”ï¸ **Cyclical Learning Rate (CLR)** scheduling
* âœ”ï¸ **Extensive preprocessing + augmentation**
* âœ”ï¸ **286k histopathology patches** processed (50Ã—50 RGB images)
* âœ”ï¸ **86.05% test accuracy** on unseen patients

---

## ğŸ“‚ Dataset

**Source:** Breast Histopathology Images (Kaggle)

### Structure:

```
/patient_id/
    â”œâ”€â”€ 0/  # Benign patches
    â””â”€â”€ 1/  # IDC-positive patches
```

### Stats:

* **Total patches:** 277,524
* **Class distribution:**

  * 198,738 benign
  * 78,786 IDC-positive
* **Patients:** 280
* **Patch size:** 50Ã—50 RGB

> âš ï¸ Highly imbalanced dataset â€” handled using class weighting.

---

## ğŸ› ï¸ Methodology

### 1ï¸âƒ£ Data Preprocessing

* Resize to 50Ã—50 px
* Normalize with ImageNet statistics
* Data augmentation:

  * Random horizontal flip
  * Random vertical flip

---

### 2ï¸âƒ£ Patient-Level Split (No leakage)

```
70% Train  
15% Validation  
15% Test  
```

All patches from a patient stay inside the same split.

---

### 3ï¸âƒ£ Model Architecture

Using **ResNet18 (pre-trained on ImageNet)** as feature extractor.

ğŸ§  **Custom classification head:**

* Linear â†’ ReLU â†’ BatchNorm â†’ Dropout (0.5)
* Linear â†’ ReLU â†’ BatchNorm â†’ Dropout (0.5)
* Final Linear â†’ 2 output classes

---

### 4ï¸âƒ£ Handling Imbalance

Used **compute_class_weight('balanced')** to calculate weights for weighted cross-entropy.

---

### 5ï¸âƒ£ Optimization

* **Optimizer:** SGD
* **Learning Rate Scheduler:** CyclicLR

  * Helps escape local minima
  * Improves convergence

---

## ğŸ“Š Model Performance

### âœ”ï¸ Fast, stable convergence

Even after **1 epoch**, the model showed strong learning patterns.
Training for 30 epochs (recommended) yields smoother convergence and higher accuracy.

### âœ”ï¸ Final Test Set Accuracy: **86.05%**

Evaluated on unseen patient patches.

### âœ”ï¸ Loss Curves

Loss decreased consistently across training, validation, and testing.

---

## ğŸ§  Insights

* **Patient-level splitting** is crucial â€” otherwise model overfits.
* **Weighted loss + CLR** significantly boosts performance on minority class.
* The model generalizes well despite dataset imbalance.
* Patch-based classification works, but loses spatial context of whole slides.

---

## ğŸ Project Assessment

### Strengths:

* High accuracy
* Strong generalization
* Robust pipeline (augmentation, splitting, weighting, CLR)
* Applicable as a **decision-support system** for pathologists

### Limitations:

* Dataset sourced from a **single institution**
* Patch classification loses tumor shape/spatial reasoning
* Only 280 patient samples

---

## ğŸ”® Future Work

* ğŸ—‚ï¸ **Use larger, multi-institution datasets**
* ğŸ–¼ï¸ **Whole Slide Image (WSI) analysis** instead of patch-based
* âš¡ **Try modern architectures** like EfficientNet or Vision Transformers
* ğŸ” **Add explainability** using Grad-CAM
* ğŸ¯ **Hyperparameter tuning + longer training (30+ epochs)**

---

## ğŸ§¾ Conclusion

This project successfully demonstrates the potential of deep learning to classify IDC in breast tissue patches.
With **ResNet18**, balanced loss, and a smart optimization setup, the model achieved **86.05% accuracy** on unseen patients â€” showing how AI can speed up screening and support pathologists in real clinical settings.

Further improvements (WSI analysis, larger datasets, explainability) could move this from a proof-of-concept to a deployable clinical tool.
